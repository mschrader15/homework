{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy21 Task #2 & 3\n",
    "\n",
    "Max Schrader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from enum import Enum\n",
    "from random import uniform, randint, choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bust(score):\n",
    "    if (score < 1) or (score > 21):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cards:\n",
    "    def __init__(self):\n",
    "        self.distribution_range = (1, 10)\n",
    "    \n",
    "    def get_card(self, first=False):\n",
    "        return randint(*self.distribution_range) * 1 if (uniform(0, 1) < 2/3) or first else -1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._initialize()\n",
    "        \n",
    "    def _initialize(self):\n",
    "        self._cards = []\n",
    "    \n",
    "    def set_first(self, card):\n",
    "        self._initialize()\n",
    "        self._cards.append(card)\n",
    "        \n",
    "    def _add_to_hand(self, card):\n",
    "        self._cards.append(card)\n",
    "        \n",
    "    def _sum(self, ):\n",
    "        return sum(self._cards)\n",
    "    \n",
    "    def play_hand(self, card):\n",
    "        self._add_to_hand(card)\n",
    "        return self._my_game_plan()\n",
    "    \n",
    "    def _my_game_plan(self, ):\n",
    "        if not check_bust(self._sum()):\n",
    "            Action.HIT\n",
    "        return Action.STICK\n",
    "    \n",
    "    def get_sum(self):\n",
    "        return self._sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dealer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dealer(Player):\n",
    "    \n",
    "    STICK_THRESHOLD = 17\n",
    "    \n",
    "    def __init__(self, card_obj):\n",
    "        super().__init__()\n",
    "        self._card_deck = card_obj\n",
    "\n",
    "    def draw_card(self, first=False):\n",
    "        return self._card_deck.get_card()\n",
    "    \n",
    "    def _my_gameplan(self, ):\n",
    "        current_sum = self._get_sum()\n",
    "        if (current_sum < 1) or (current_sum > 21):\n",
    "            return False\n",
    "        if current_sum < Dealer.STICK_THRESHOLD:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def take_turns(self, ):\n",
    "        while self._my_gameplan():\n",
    "            self._add_to_hand(self.draw_card())\n",
    "#         return self._sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Observed State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, dealer_first_card, ):\n",
    "        self.dealer_card = dealer_first_card\n",
    "        self.player_sum = 0\n",
    "        self.dealer_action = None\n",
    "    \n",
    "    def update_sum(self, player_sum):\n",
    "        self.player_sum += player_sum\n",
    "        \n",
    "    def update_action(dealer_action):\n",
    "        self.dealer_action = dealer_action\n",
    "        \n",
    "        \n",
    "class Action(Enum):\n",
    "    STICK = 0\n",
    "    HIT = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Easy21:\n",
    "    \n",
    "    REWARD = {'bust': -1, 'win': 1, 'draw': 0}\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dealer = Dealer(Cards())\n",
    "        self.player = None\n",
    "        self.state = None\n",
    "        self.state_space = [[(j + 1, i + 1) for i in range(10)] for j in range(21)]\n",
    "        self.action_space = ['hit', 'stick']\n",
    "    \n",
    "    def get_reward(self, player_sum):\n",
    "        if _check_bust(self.dealer.get_score()) or (player_sum > self.dealer.get_score()):\n",
    "            return 1\n",
    "        return 0 if player_sum == self.dealer.get_score() else -1\n",
    "    \n",
    "    def add_player(self, player):\n",
    "        self.player = player\n",
    "    \n",
    "    def step(self, current_state, player_action):\n",
    "        terminal = True\n",
    "        if player_action == Action.STICK:\n",
    "            self.dealer.take_turns()\n",
    "            r = self.get_reward(current_state.player_sum)\n",
    "        else:\n",
    "            next_card = self.dealer.draw_card()\n",
    "            action = self.player.play_hand(next_card)\n",
    "            current_state.update_sum(self.player.get_sum())\n",
    "            if action != action.STICK:\n",
    "                r = self.get_reward(current_state.player_sum)\n",
    "                terminal = False\n",
    "            else:\n",
    "                r = -1\n",
    "        return current_state, r, terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonteCarloAgent(Player):\n",
    "    def __init__(self, game_environment: Easy21,):\n",
    "        super().__init__()\n",
    "        self.game = game_environment\n",
    "        self.Q = [[[0 for _ in range(len(self.game.action_space))] \n",
    "                   for _ in range(len(space))] for space in self.game.state_space]\n",
    "        self.N = [[{'state': 0, 'action': [0, 0]} for _ in range(len(space))] for space in self.game.state_space]\n",
    "        self.N_0 = 100\n",
    "    \n",
    "    def _get_optimal_action(self, state):\n",
    "        rewards = self.Q[state.player_sum][state.dealer_card]\n",
    "        max_reward = max(rewards)\n",
    "        return choice([i for i, reward in enumerate(rewards) if reward >= max_reward])\n",
    "    \n",
    "    def e_greedy(self, e, state):\n",
    "        if random() < e:\n",
    "            return randint(0, 1)  # only two choices\n",
    "        return self,_get_optimal_action(state)\n",
    "    \n",
    "    def _calc_e(self, state):\n",
    "        return self.N_0 / (self.N_0 + self.N[state.player_sum][state.dealer_card]['state'])\n",
    "    \n",
    "    def _run(self, ):\n",
    "        terminal = False\n",
    "        game = Easy21()\n",
    "        t = 0\n",
    "        s_t = \n",
    "        while True:\n",
    "            s_t, r_t, terminal = game.step()\n",
    "            if terminal:\n",
    "                break\n",
    "            a_t = self.e_greedy(self._calc_e(state), state)\n",
    "            self.N[s_1.player_sum][s_1.dealer_card]['state'] += 1\n",
    "            self.N[s_1.player_sum][s_1.dealer_card]['action'][a_1] += 1\n",
    "            self.Q[s_1.player_sum][s_1.dealer_card][a_1] += (1 / self.N[s_1.player_sum][s_1.dealer_card]['action'][a_1]) * \\\n",
    "                (r_t - self.Q[s_1.player_sum][s_1.dealer_card][a_1])\n",
    "            t += 1\n",
    "        return t\n",
    "    \n",
    "    def optimize(self, iterations):\n",
    "        for iteration in range(iterations):\n",
    "            self._run()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_agent = MonteCarloAgent(game_environment=Easy21(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "step() missing 2 required positional arguments: 'current_state' and 'player_action'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-521dd490d4ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmc_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-b40e0885e0ed>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, iterations)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-b40e0885e0ed>\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0ms_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: step() missing 2 required positional arguments: 'current_state' and 'player_action'"
     ]
    }
   ],
   "source": [
    "mc_agent.optimize(iterations=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
