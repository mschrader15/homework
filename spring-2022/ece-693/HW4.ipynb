{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mschrader15/homework/blob/main/spring-2022/ece-693/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVy5gXAv5pHQ"
      },
      "source": [
        "# **Introduction**\n",
        "\n",
        "This homework explores forecasting on time series. We will attempt to develop a model that forecasts the closing price of a stock one week in the future. The model ideally should work for any company on the stock market."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2nE91Dn5pHT"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The dataset used in this assignment is available from Kaggle: Stock Prediction using Linear Regression - Starter\n",
        "https://www.kaggle.com/code/nikhilkohli/stock-prediction-using-linear-regression-starter/data\n",
        "\n",
        "Note that the dataset consists of multiple files:\n",
        "\n",
        "AAPL.csv\n",
        "AMZN.csv\n",
        "FB.csv\n",
        "GE.csv\n",
        "GOOGL.csv\n",
        "GS.csv\n",
        "IBM.csv\n",
        "JPM.csv\n",
        "MSFT.csv\n",
        "TSLA.csv\n",
        "\n",
        "** Please keep the dataset files in directory specified by the variable dataset_path **\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pathlib\n",
        "dataset_path=pathlib.Path('D:\\\\data\\\\stockdata')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_uEEh0aV5pHU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoRHiBr95pHW"
      },
      "source": [
        "# **Task 1: inspecting the dataset and selecting important features**\n",
        "\n",
        "The files contain 64 columns and ~3000 rows. Not all columns are meaningful predictors.\n",
        "Your goal is to keep the features that have predictive power.\n",
        "There are many ways to select meaningful features, here we will try one of the methods developed specifically for deep learning models.\n",
        "\n",
        "SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model.\n",
        "The suggested way to select features is to use SHAP with the linear regression model provided at the dataset's Kaggle page.\n",
        "SHAP is available at https://github.com/slundberg/shap\n",
        "The page provides several examples of using SHAP, including examples with regression models and Keras.\n",
        "\n",
        "Method:\n",
        "Use SHAP library to generate SHAP score for each of the 64 columns (features).\n",
        "Note that the results may vary from company to company.\n",
        "Generate SHAP score graphs, set a threshold, keep only the features with the score above the threshold.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_sz3QrW5pHX"
      },
      "outputs": [],
      "source": [
        "#Your solution here\n",
        "\n",
        "#The selected features should be kept in a tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef8WzVKk5pHX"
      },
      "source": [
        "**Plotting the timeseries**\n",
        "Generate a plot of the selected features vs time on different scales, note any periodicity or lack thereof"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oj0UL_ex5pHY"
      },
      "outputs": [],
      "source": [
        "#code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gglRQxTp5pHY"
      },
      "source": [
        "**Normalizing the data**\n",
        "If needed, normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "#Your code here"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JGQvHR9f5pHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the data into training, validation and test datasets**\n",
        "Use the book/lecture materials to produce the datasets.\n",
        "in the report comment on the size and techniques used, especially in regard to using different companies."
      ],
      "metadata": {
        "collapsed": false,
        "id": "cFYeC3y95pHZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEBSz5Yy5pHZ"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgDyry-j5pHZ"
      },
      "source": [
        "# **Task 2: a baseline model**\n",
        "Use any empirical model or a simple machine learning model (e.g. linear regression of the stock price) to predict the price one week in the future from the current date.\n",
        "Establish a quantitative accuracy measure and evaluate the accuracy of the model.\n",
        "\n",
        "*Note that the linear regression suggested above is not the same as given in sample code!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxmgynrM5pHa"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0snAwso05pHa"
      },
      "source": [
        "# **Task 3: training deep learning models**\n",
        "Train the following models for forecasting:\n",
        "1. Based on the Dense layer(s)\n",
        "2. Based on LSTM layer(s)\n",
        "3. Based on GRU layers(s)\n",
        "\n",
        "The selection of model parameters is completely up to you.\n",
        "You need, however, to investigate and provide in the report:\n",
        "1. Effect of stacked models\n",
        "2. Effect of dropout\n",
        "Quantify the accuracy of each model\n",
        "\n",
        "**Save the trained models to the same directory as the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Q3g3owbb5pHb"
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 4: plotting predictions**\n",
        "Load the trained model from the disk. This is required for me to check the forecast.\n",
        "Use the variable shown below to specify the company for which we are making the forecast.\n",
        "Load the data for the company in the range that was not used for training/validation.\n",
        "\n",
        "Perform inference and plot the forecast values vs actual values.\n",
        "Print the mean square error of the forecast.\n",
        "\n",
        "*Note: Since the data needs to be loaded from disk, the code will be much more compact if the loading/feature selection/normalization are made into functions.\n",
        "*Note: no need to repeat feature selection here. Use previosuly establsihed indices of selected features."
      ],
      "metadata": {
        "collapsed": false,
        "id": "aRIxTYmI5pHb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "#company to be used in prediction\n",
        "forecast_for_stock='GOOGL.csv'\n",
        "\n",
        "#your code here"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kEjUiKrp5pHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Grading**\n",
        "(10 pts) Report quality / submission requirement followed (see class policy)\n",
        "(90 pts) Equally split between Task 1 - Task 3"
      ],
      "metadata": {
        "collapsed": false,
        "id": "GwVt9hWR5pHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Submission**\n",
        "Using Blackboard, submit the .ipynb file, the dataset files, saved models and the report in a compressed folder as defined by the class policy.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "5PxYxASA5pHd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "5CevP4FI5pHd"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HW4.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}